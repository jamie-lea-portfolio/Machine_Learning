
\newcommand{\Dataset}{\mathcal{D}}
\newcommand{\Experiment}{\mathcal{E}}

    \text{because when $h$ does not depend on $u$, and because}&\Expect_{\epsilon}[\epsilon] = 0), 
        \Expect_{\epsilon[\epsilon h] = 0, 
        \Expect_{u,v}[h(v) = \Expect_{v}[h(v)]
    \\
    
    
        \\
    \text{since } \Expect_{u,v}[h(v)] = \Expect[h(v)], \quad \Expect_{\epsilon}[\epsilon] = 0,
    \\
    
        \begin{align*}
        a^{(\Data)} &= \frac{x_{2}^{2} - x_{1}^{2}}{x_{2} - x_{1}} \\
        &= x_{2} + x_{1} \\
        b^{(\Data)} &= x_{1}^{2} - a x_{1} \\
        &= x_{1}^{2} - (x_{2} + x_{1})x_{1}\\
    \end{align*}
    
        

    \begin{align*}
        \gD(x) &= (x_{2} + x_{1})x + x_{1}^{2} - (x_{2} + x_{1})x_{1} \\
        &= x_{2}x + x_{1}x - x_{2}x_{1}
    \end{align*}
    
    
    \begin{align*}
        a^{(\Data)} &= \frac{x_{2}^{2} - x_{1}^{2}}{x_{2} - x_{1}} & b^{(\Data)} &= x_{1}^{2} - a^{(\Data)} x_{1} = x_{1}^{2} - (x_{2} + x_{1})x_{1}\\
        &= x_{2} + x_{1} && = -x_{2}x_{1}
    \end{align*}
    \begin{align*}
    a^{(\Data)} &= \frac{x_{2}^{2} - x_{1}^{2}}{x_{2} - x_{1}} = x_{2} + x_{1} \\
    b^{(\Data)} &= x_{1}^{2} - a^{(\Data)} x_{1} = x_{1}^{2} - (x_{2} + x_{1})x_{1}\\
    & = -x_{2}x_{1}
    \end{align*}
    